{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpar5LziY_-0"
      },
      "source": [
        "#Zadanie 4 (7 pkt)\n",
        "Celem zadania jest zaimplementowanie algorytmu drzewa decyzyjnego ID3 dla zadania klasyfikacji. Trening i test należy przeprowadzić dla zbioru Iris. Proszę przeprowadzić eksperymenty najpierw dla DOKŁADNIE takiego podziału zbioru testowego i treningowego jak umieszczony poniżej. W dalszej części należy przeprowadzić analizę działania drzewa dla różnych wartości parametrów. Proszę korzystać z przygotowanego szkieletu programu, oczywiście można go modyfikować według potrzeb. Wszelkie elementy szkieletu zostaną wyjaśnione na zajęciach.\n",
        "\n",
        "* Implementacja funkcji entropii - **0.5 pkt**\n",
        "* Implementacja funkcji entropii zbioru - **0.5 pkt**\n",
        "* Implementacja funkcji information gain - **0.5 pkt**\n",
        "* Zbudowanie poprawnie działającego drzewa klasyfikacyjnego i przetestowanie go na wspomnianym wcześniej zbiorze testowym. Jeśli w liściu występuje kilka różnych klas, decyzją jest klasa większościowa. Policzenie accuracy i wypisanie parami klasy rzeczywistej i predykcji. - **4 pkt**\n",
        "* Przeprowadzenie eksperymentów dla różnych głębokości drzew i podziałów zbioru treningowego i testowego (zmiana wartości argumentu test_size oraz usunięcie random_state). W tym przypadku dla każdego eksperymentu należy wykonać kilka uruchomień programu i wypisać dla każdego uruchomienia accuracy. - **1.5 pkt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XNc-O3npA-J9"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fBh2tfQ44u5k"
      },
      "outputs": [],
      "source": [
        "def entropy_func(class_count, num_samples):\n",
        "    entropy = 0\n",
        "    for count in class_count.values():\n",
        "        probability = count / num_samples\n",
        "        entropy -= probability * math.log2(probability)\n",
        "    return entropy\n",
        "\n",
        "\n",
        "class Group:\n",
        "    def __init__(self, group_classes):\n",
        "        self.group_classes = group_classes\n",
        "        self.entropy = self.group_entropy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.group_classes.size\n",
        "\n",
        "    def group_entropy(self):\n",
        "        class_count = Counter(self.group_classes)\n",
        "        return entropy_func(class_count, len(self.group_classes))\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, split_feature, split_val, depth=None, child_node_a=None, child_node_b=None, val=None):\n",
        "        self.split_feature = split_feature\n",
        "        self.split_val = split_val\n",
        "        self.depth = depth\n",
        "        self.child_node_a = child_node_a\n",
        "        self.child_node_b = child_node_b\n",
        "        self.val = val\n",
        "\n",
        "    def predict(self, data):\n",
        "        pass\n",
        "\n",
        "\n",
        "class DecisionTreeClassifier(object):\n",
        "    def __init__(self, max_depth):\n",
        "        self.depth = 0\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    @staticmethod\n",
        "    def get_split_entropy(group_a, group_b):\n",
        "        pass\n",
        "\n",
        "    def get_information_gain(self, parent_group, child_group_a, child_group_b):\n",
        "        pass\n",
        "\n",
        "    def get_best_feature_split(self, feature_values, classes):\n",
        "        pass\n",
        "\n",
        "    def get_best_split(self, data, classes):\n",
        "        pass\n",
        "\n",
        "    def build_tree(self, data, classes, depth=0):\n",
        "        pass\n",
        "\n",
        "    def predict(self, data):\n",
        "        return self.tree.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U033RY1_YS8x"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'numpy.ndarray'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/szczygiel/wsi/Zadanie_4.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# dc = DecisionTreeClassifier(3)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# dc.build_tree(x_train, y_train)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# for sample, gt in zip(x_test, y_test):\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     prediction = dc.predict(sample)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m x_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(x_train)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m class_count \u001b[39m=\u001b[39m Counter(x_list)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m num \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(class_count\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/szczygiel/wsi/Zadanie_4.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m result \u001b[39m=\u001b[39m entropy_func(class_count, num)\n",
            "File \u001b[0;32m/usr/lib/python3.10/collections/__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mof elements to their counts.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 577\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(iterable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
            "File \u001b[0;32m/usr/lib/python3.10/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mupdate(iterable)\n\u001b[1;32m    669\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         _count_elements(\u001b[39mself\u001b[39;49m, iterable)\n\u001b[1;32m    671\u001b[0m \u001b[39mif\u001b[39;00m kwds:\n\u001b[1;32m    672\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(kwds)\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ],
      "source": [
        "# dc = DecisionTreeClassifier(3)\n",
        "# dc.build_tree(x_train, y_train)\n",
        "# for sample, gt in zip(x_test, y_test):\n",
        "#     prediction = dc.predict(sample)\n",
        "x_list = list(x_train)\n",
        "class_count = Counter(x_list)\n",
        "num = sum(class_count.values())\n",
        "result = entropy_func(class_count, num)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
